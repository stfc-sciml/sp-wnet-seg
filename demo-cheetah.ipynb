{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc17564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage.filters import unsharp_mask\n",
    "from skimage.io import imread\n",
    "from skimage.morphology import remove_small_objects, remove_small_holes, dilation\n",
    "from skimage.segmentation import slic, mark_boundaries, find_boundaries\n",
    "from skimage.transform import rescale\n",
    "\n",
    "from src.train_predict import train_sp_wnet, predict_sp_wnet\n",
    "from src.utils import im_crop_multiple, sample_patch_datasets\n",
    "from src.wnet import WNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = {\"axes.spines.left\": False,\n",
    "      \"axes.spines.right\": False,\n",
    "      \"axes.spines.bottom\": False,\n",
    "      \"axes.spines.top\": False,\n",
    "      \"xtick.bottom\": False,\n",
    "      \"xtick.labelbottom\": False,\n",
    "      \"ytick.labelleft\": False,\n",
    "      \"ytick.left\": False,\n",
    "      \"figure.dpi\": 200}\n",
    "plt.rcParams.update(rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515dcff",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb585722",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_image(fname, cut=0, scale=1, unit=1, unsharp_par=None):\n",
    "    img = imread(fname)\n",
    "    if cut > 0:\n",
    "        img = img[cut:-cut, cut:-cut]\n",
    "    img = rescale(img, scale, multichannel=True)\n",
    "    img = im_crop_multiple(img, unit)\n",
    "    if unsharp_par is not None:\n",
    "        img = unsharp_mask(img, radius=unsharp_par[0], amount=unsharp_par[1])\n",
    "    return img.astype('float32')\n",
    "\n",
    "\n",
    "def read_image_nn(fname):\n",
    "    return read_image(fname, cut=10, scale=1/3, unit=16, \n",
    "                      unsharp_par=(5, 1))\n",
    "\n",
    "\n",
    "# select image for training\n",
    "folder = f'data/videos/cheetah'\n",
    "iids = [10, 123, 270, 370]\n",
    "image_in_list = []\n",
    "for iid in iids:\n",
    "    image_in = read_image_nn(f'{folder}/clips/{iid:04d}.jpg')\n",
    "    image_in_list.append(image_in)\n",
    "    print('Shape of input image:', image_in.shape)\n",
    "    plt.imshow(image_in)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869cd747",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 8\n",
    "side_sizes = [64, 96]\n",
    "count_per_batch_for_max_size = 4\n",
    "total_pixels_per_batch = max(side_sizes) ** 2 * count_per_batch_for_max_size\n",
    "shapes_and_counts = []\n",
    "for sx in side_sizes:\n",
    "    for sy in side_sizes:\n",
    "        if sy * 2 >= sx >= sy // 2:\n",
    "            shapes_and_counts.append(\n",
    "                (sx, sy, total_pixels_per_batch // (sx * sy)))\n",
    "\n",
    "image_tensor_list = []\n",
    "image_patches_list = []\n",
    "for i, image_in in enumerate(image_in_list):\n",
    "    image_patches = sample_patch_datasets(\n",
    "        image_in, shapes_and_counts=shapes_and_counts,\n",
    "        n_batches=n_batches, seed=i, returns_image_tensor=False)\n",
    "    image_tensor_list.append(torch.from_numpy(np.moveaxis(image_in, -1, -3)))\n",
    "    image_patches_list.append(image_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa3b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot patches\n",
    "for image_tensor, image_patches in zip(image_tensor_list, image_patches_list):\n",
    "    fig, ax = plt.subplots(1, len(image_patches) + 1, dpi=400)\n",
    "    for i, (dx, dy, count) in enumerate(shapes_and_counts):\n",
    "        idx = np.random.choice(len(image_patches[i]))\n",
    "        ax[i].imshow(image_patches[i][idx].permute(1, 2, 0))\n",
    "        ax[i].set_title(f'[{dx} x {dy}], {count} imgs/batch', fontsize=3)\n",
    "    ax[-1].imshow(image_tensor.permute(1, 2, 0))\n",
    "    ax[-1].set_title(f'original', fontsize=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d656bc",
   "metadata": {},
   "source": [
    "# Superpixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b214736",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_sp(img):\n",
    "    return slic(img.astype(float), n_segments=12000,\n",
    "                compactness=10, sigma=1, start_label=0)\n",
    "\n",
    "image_sp_list = []\n",
    "for image_in in image_in_list:\n",
    "    image_sp = make_sp(image_in)\n",
    "    image_sp_list.append(image_sp)\n",
    "    plt.figure(dpi=200)\n",
    "    plt.imshow(mark_boundaries(image_in, image_sp))\n",
    "    plt.title(f'superpixels, N={len(np.unique(image_sp))}', fontsize=5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644190c2",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320e7a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "re_train = True\n",
    "if re_train:\n",
    "    # clear results\n",
    "    os.system(f'rm -rf {folder}/results/*')\n",
    "    Path(f'{folder}/results').mkdir(exist_ok=True)\n",
    "    # create wnet\n",
    "    seed = 84\n",
    "    torch.manual_seed(seed)\n",
    "    wnet = WNet(3, 32, ch_mul=64, n_blocks=4)\n",
    "    # train\n",
    "    hist = train_sp_wnet(\n",
    "        wnet,\n",
    "        # image data\n",
    "        image_tensor_list, image_patches_list=image_patches_list, n_batches=n_batches,\n",
    "        # superpixel\n",
    "        image_sp_list=image_sp_list, sp_seg_mode='argmax_of_mean',\n",
    "        tau_cut='unused', tau_sim_kmeans='unused', k_kmeans='unused', tau_con=1.,\n",
    "        use_sparse_adj=True,\n",
    "        # beta values\n",
    "        beta_rc_image=.5, beta_rc_patches=1.,\n",
    "        beta_cut=None, beta_sim=.1, beta_con=.1,\n",
    "        # results after each epoch\n",
    "        plot_epoch=True, save_epoch_results_to='screen',\n",
    "        # others\n",
    "        epochs=15, lr=0.001, device='cuda', progress_bar=True)\n",
    "    # save weights\n",
    "    torch.save(wnet.state_dict(), f'{folder}/results/wnet.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16290813",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc4c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(wnet_model, iid_pred, merge_list=None):\n",
    "    # predict\n",
    "    img_pred = read_image_nn(f'{folder}/clips/{iid_pred:04d}.jpg')\n",
    "    img_pred_tensor = torch.from_numpy(np.moveaxis(img_pred, -1, -3))\n",
    "    img_sp_pred = make_sp(img_pred)\n",
    "    ft_img_list, rc_img_list, label_img_list = predict_sp_wnet(\n",
    "        wnet_model, [img_pred_tensor], image_sp_list=[img_sp_pred],\n",
    "        sp_seg_mode='argmax_of_mean', device='cuda',\n",
    "        make_label_continuous=True, returns_in_numpy=True)\n",
    "\n",
    "    # post-processing on labels\n",
    "    img_label = label_img_list[0]\n",
    "    if merge_list is not None:\n",
    "        for merge in merge_list:\n",
    "            for idx_merge in merge:\n",
    "                img_label[img_label == idx_merge] = min(merge)\n",
    "    return img_pred, img_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7411f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show some predictions\n",
    "iids = [9, 90, 233, 252]\n",
    "fig, ax = plt.subplots(1, len(iids), dpi=200, figsize=(10, 2))\n",
    "wnet = WNet(3, 32, ch_mul=64, n_blocks=4)\n",
    "wnet.load_state_dict(torch.load(f'{folder}/results/wnet.pt'))\n",
    "for j, iid in enumerate(iids):\n",
    "    image_pred, label_pred = predict(wnet, iid)\n",
    "    ax[j].imshow(label_pred, cmap='rainbow')\n",
    "    for lab in np.unique(label_pred):\n",
    "        x, y = np.where(label_pred == lab)\n",
    "        x_mean, y_mean = np.mean(x), np.mean(y)\n",
    "        ax[j].text(y_mean, x_mean, str(lab))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4f73b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Path(f'{folder}/results/label').mkdir(exist_ok=True)\n",
    "Path(f'{folder}/results/mark').mkdir(exist_ok=True)\n",
    "\n",
    "# load model\n",
    "wnet = WNet(3, 32, ch_mul=64, n_blocks=4)\n",
    "wnet.load_state_dict(torch.load(f'{folder}/results/wnet.pt'))\n",
    "\n",
    "# labels to be merged for background\n",
    "merges = [[0, 1, 3]]\n",
    "bkg_label = merges[0][0]\n",
    "obj_label = 2\n",
    "sky_label = 4\n",
    "\n",
    "for iid in range(1, 403):\n",
    "    print(iid)\n",
    "    # label images\n",
    "    image_pred, label_pred = predict(wnet, iid, merge_list=merges)\n",
    "    # remove small holes in background\n",
    "    b = remove_small_holes(label_pred == bkg_label, 100)\n",
    "    label_pred[b] = bkg_label\n",
    "    # change small sky patches to object\n",
    "    b = remove_small_objects(label_pred == sky_label, 10000)\n",
    "    label_pred[label_pred == sky_label - b] = obj_label\n",
    "    plt.imshow(label_pred, cmap='rainbow')\n",
    "    plt.savefig(f'{folder}/results/label/{iid:04d}.jpg', \n",
    "                bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    \n",
    "    # boundary images\n",
    "    # upscale label image to original size\n",
    "    size_before_round = read_image(f'{folder}/clips/{iid:04}.jpg', \n",
    "                                   cut=10, scale=1/3, unit=1, unsharp_par=None).shape\n",
    "    label_up = np.full((size_before_round[0], size_before_round[1]), \n",
    "                       fill_value=bkg_label, dtype=int)\n",
    "    start0 = (label_up.shape[0] - label_pred.shape[0]) // 2\n",
    "    start1 = (label_up.shape[1] - label_pred.shape[1]) // 2\n",
    "    label_up[start0:start0 + label_pred.shape[0], \n",
    "             start1:start1 + label_pred.shape[1]] = label_pred\n",
    "    label_up = rescale(label_up, 3)\n",
    "    # find boundaries and make them thicker\n",
    "    boundaries = find_boundaries(label_up, mode='thick')\n",
    "    # plot\n",
    "    image_show = read_image(f'{folder}/clips/{iid:04d}.jpg', \n",
    "                            cut=10, scale=1, unit=1, \n",
    "                            unsharp_par=None)[:label_up.shape[0], :label_up.shape[1]]\n",
    "    image_show[boundaries] = [0, 0, 1]  # blue\n",
    "    image_show = im_crop_multiple(image_show, 64)[4:-4, 4:-4]\n",
    "    plt.imshow(image_show)\n",
    "    plt.show()\n",
    "    plt.imsave(f'{folder}/results/mark/{iid:04d}.jpg', image_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'ffmpeg -start_number 1 -y -i '\n",
    "          f'{folder}/results/label/%04d.jpg '\n",
    "          f'-vf pad=\"width=ceil(iw/2)*2:height=ceil(ih/2)*2\" '\n",
    "          f'{folder}/results/label.mp4')\n",
    "os.system(f'ffmpeg  -start_number 1 -y -i '\n",
    "          f'{folder}/results/mark/%04d.jpg '\n",
    "          f'-vf pad=\"width=ceil(iw/2)*2:height=ceil(ih/2)*2\" '\n",
    "          f'{folder}/results/mark.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a2604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
